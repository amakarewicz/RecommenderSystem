{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import scipy.sparse as sparse\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import scipy.sparse as sparse\r\n",
    "import pickle\r\n",
    "import csv\r\n",
    "import implicit\r\n",
    "import itertools\r\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>mid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ld.154103</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ld.142559</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.18331199</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>ld.144819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>ld.1293110</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   uid         mid\n0    1   ld.154103\n1    1   ld.142559\n2    1  1.18331199\n3    1   ld.144819\n4    1  ld.1293110"
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/readers.csv\")\r\n",
    "df = df.rename(columns={\"id\":\"uid\", \"art_id\":\"mid\"})\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 1000\n",
      "Number of models: 11260\n",
      "Sparsity: 0.247%\n"
     ]
    }
   ],
   "source": [
    "n_users = df.uid.unique().shape[0]\r\n",
    "n_items = df.mid.unique().shape[0]\r\n",
    "\r\n",
    "print('Number of users: {}'.format(n_users))\r\n",
    "print('Number of models: {}'.format(n_items))\r\n",
    "print('Sparsity: {:4.3f}%'.format(float(df.shape[0]) / float(n_users*n_items) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_likes(df, uid_min, mid_min):\r\n",
    "    n_users = df.uid.unique().shape[0]\r\n",
    "    n_items = df.mid.unique().shape[0]\r\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\r\n",
    "    print('Starting likes info')\r\n",
    "    print('Number of users: {}'.format(n_users))\r\n",
    "    print('Number of models: {}'.format(n_items))\r\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\r\n",
    "    \r\n",
    "    done = False\r\n",
    "    while not done:\r\n",
    "        starting_shape = df.shape[0]\r\n",
    "        mid_counts = df.groupby('uid').mid.count()\r\n",
    "        df = df[~df.uid.isin(mid_counts[mid_counts < mid_min].index.tolist())]\r\n",
    "        uid_counts = df.groupby('mid').uid.count()\r\n",
    "        df = df[~df.mid.isin(uid_counts[uid_counts < uid_min].index.tolist())]\r\n",
    "        ending_shape = df.shape[0]\r\n",
    "        if starting_shape == ending_shape:\r\n",
    "            done = True\r\n",
    "    \r\n",
    "    assert(df.groupby('uid').mid.count().min() >= mid_min)\r\n",
    "    assert(df.groupby('mid').uid.count().min() >= uid_min)\r\n",
    "    \r\n",
    "    n_users = df.uid.unique().shape[0]\r\n",
    "    n_items = df.mid.unique().shape[0]\r\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\r\n",
    "    print('Ending likes info')\r\n",
    "    print('Number of users: {}'.format(n_users))\r\n",
    "    print('Number of models: {}'.format(n_items))\r\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting likes info\n",
      "Number of users: 1000\n",
      "Number of models: 11260\n",
      "Sparsity: 0.247%\n",
      "Ending likes info\n",
      "Number of users: 795\n",
      "Number of models: 1315\n",
      "Sparsity: 1.020%\n"
     ]
    }
   ],
   "source": [
    "df_lim = threshold_likes(df, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\r\n",
    "mid_to_idx = {}\r\n",
    "idx_to_mid = {}\r\n",
    "for (idx, mid) in enumerate(df_lim[\"mid\"].unique().tolist()):\r\n",
    "    mid_to_idx[mid] = idx\r\n",
    "    idx_to_mid[idx] = mid\r\n",
    "    \r\n",
    "uid_to_idx = {}\r\n",
    "idx_to_uid = {}\r\n",
    "for (idx, uid) in enumerate(df_lim[\"uid\"].unique().tolist()):\r\n",
    "    uid_to_idx[uid] = idx\r\n",
    "    idx_to_uid[idx] = uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids(row, mapper):\r\n",
    "    return mapper[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = df_lim[\"uid\"].apply(map_ids, args=[uid_to_idx]).to_numpy()\r\n",
    "J = df_lim[\"mid\"].apply(map_ids, args=[mid_to_idx]).to_numpy()\r\n",
    "V = np.ones(I.shape[0])\r\n",
    "likes = sparse.coo_matrix((V, (I, J)), dtype=np.float64)\r\n",
    "likes = likes.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, split_count, fraction=None):\r\n",
    "    \"\"\"\r\n",
    "    Split recommendation data into train and test sets\r\n",
    "    \r\n",
    "    Params\r\n",
    "    ------\r\n",
    "    ratings : scipy.sparse matrix\r\n",
    "        Interactions between users and items.\r\n",
    "    split_count : int\r\n",
    "        Number of user-item-interactions per user to move\r\n",
    "        from training to test set.\r\n",
    "    fractions : float\r\n",
    "        Fraction of users to split off some of their\r\n",
    "        interactions into test set. If None, then all \r\n",
    "        users are considered.\r\n",
    "    \"\"\"\r\n",
    "    # Note: likely not the fastest way to do things below.\r\n",
    "    train = ratings.copy().tocoo()\r\n",
    "    test = sparse.lil_matrix(train.shape)\r\n",
    "    \r\n",
    "    if fraction:\r\n",
    "        try:\r\n",
    "            user_index = np.random.choice(\r\n",
    "                np.where(np.bincount(train.row) >= split_count * 2)[0], \r\n",
    "                replace=False,\r\n",
    "                size=np.int32(np.floor(fraction * train.shape[0]))\r\n",
    "            ).tolist()\r\n",
    "        except:\r\n",
    "            print(('Not enough users with > {} '\r\n",
    "                  'interactions for fraction of {}')\\\r\n",
    "                  .format(2*k, fraction))\r\n",
    "            raise\r\n",
    "    else:\r\n",
    "        user_index = range(train.shape[0])\r\n",
    "        \r\n",
    "    train = train.tolil()\r\n",
    "\r\n",
    "    for user in user_index:\r\n",
    "        test_ratings = np.random.choice(ratings.getrow(user).indices, \r\n",
    "                                        size=split_count, \r\n",
    "                                        replace=False)\r\n",
    "        train[user, test_ratings] = 0.\r\n",
    "        # These are just 1.0 right now\r\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\r\n",
    "   \r\n",
    "    \r\n",
    "    # Test and training are truly disjoint\r\n",
    "    assert(train.multiply(test).nnz == 0)\r\n",
    "    return train.tocsr(), test.tocsr(), user_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, user_index = train_test_split(likes, 5, fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(795, 1315)"
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(795, 1315)"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(model, ratings, k=5, user_index=None):\r\n",
    "    if not user_index:\r\n",
    "        user_index = range(ratings.shape[0])\r\n",
    "\r\n",
    "    ratings = ratings.tocsr()\r\n",
    "    precisions = []\r\n",
    "    # Note: line below may become infeasible for large datasets.\r\n",
    "    for user in user_index:\r\n",
    "        # In case of large dataset, compute predictions row-by-row like below\r\n",
    "        # predictions = np.array([model.predict(row, i) for i in xrange(ratings.shape[1])])\r\n",
    "        #top_k = np.argsort(-predictions[user, :])[:k]\r\n",
    "        top_k = model(user, N=k)\r\n",
    "        #print(top_k)\r\n",
    "        #top_k = [idx for idx, confidence in top_k]\r\n",
    "        labels = ratings.getrow(user).indices\r\n",
    "        #print(len(set(top_k) & set(labels)))\r\n",
    "        precision = float(len(set(top_k) & set(labels))) / float(k)\r\n",
    "        precisions.append(precision)\r\n",
    "    return np.mean(precisions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(model, ratings, k=5, user_index=None):\r\n",
    "    if not user_index:\r\n",
    "        user_index = range(ratings.shape[0])\r\n",
    "\r\n",
    "    recalls = []\r\n",
    "    for user in user_index:\r\n",
    "        top_k = model(user, N=k)\r\n",
    "        #print(top_k)\r\n",
    "        #top_k = [idx for idx, confidence in top_k]\r\n",
    "        labels = test.getrow(user).indices\r\n",
    "        #print(labels)\r\n",
    "        #print(len(set(top_k) & set(labels)))\r\n",
    "        recall = float(len(set(top_k) & set(labels))) / float(len(set(labels)))\r\n",
    "        recalls.append(recall)\r\n",
    "    \r\n",
    "    return np.mean(recalls)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CF Model\r\n",
    "from scipy.sparse.linalg import svds\r\n",
    "\r\n",
    "n_latent_factors = 100\r\n",
    "\r\n",
    "U, sigma, Vt = svds(train, k=n_latent_factors)\r\n",
    "sigma = np.diag(sigma)\r\n",
    "\r\n",
    "reader_predictions = np.dot(np.dot(U, sigma), Vt)\r\n",
    "reader_predictions_norm = (reader_predictions - reader_predictions.min()) / (\r\n",
    "        reader_predictions.max() - reader_predictions.min()\r\n",
    ")\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = reader_predictions_norm[1].argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, N):\r\n",
    "    recoms = reader_predictions_norm[user_id].argsort()[-N:][::-1]\r\n",
    "    return recoms\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  15,    9,   12,   16,   10,    8,    7,   13,   11, 1066,   14,\n         18,  236,  600,  230,  766,  735,  604,  601,   17,  936, 1280,\n        857,  972,  885,  605, 1215,  768, 1074,  351,  779,   94, 1180,\n        656,  461,  720,  239, 1289,  879,  273,  340,  485,  983, 1059,\n        208, 1130,  494,  635,  584, 1093, 1003,  680,  247,  943,  938,\n       1244, 1112,  568,  123,  971,   75, 1083,  542,  772, 1085,  823,\n        102,  655,  332,  969,  382, 1173, 1076,  719,  434, 1155,   67,\n       1024,  117,  218,  321,  593,  982,  617, 1021,   28,  354,  773,\n        871,   38,  560,   79,  267,  572, 1163,  516,  863,  853, 1051,\n        536], dtype=int64)"
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019496855345911952\n",
      "0.017610062893081764\n",
      "0.038993710691823905\n"
     ]
    }
   ],
   "source": [
    "print(precision_at_k(recommend, test,k=10, user_index=user_index))\r\n",
    "print(recall_at_k(recommend, test,k=5, user_index=user_index))\r\n",
    "print(recall_at_k(recommend, test,k=10, user_index=user_index))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld.150497\n",
      "ld.150557\n",
      "ld.147049\n",
      "ld.147794\n",
      "ld.141732\n",
      "ld.1293241\n",
      "ld.152926\n",
      "ld.138548\n",
      "ld.141745\n",
      "ld.142444\n"
     ]
    }
   ],
   "source": [
    "for index in indices:\r\n",
    "    print(idx_to_mid[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([32, 33, 34, 35, 36, 37, 38, 39])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.getrow(3).indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('python-3.8.8.amd64')",
   "name": "python388jvsc74a57bd0fa40d802589a21bf16ea36e6cbe213719a0e5ddda597750d0ec239eff626732c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}