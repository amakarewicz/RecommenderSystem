{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd058acd5bd797a08523d99af27523988877810b63fdf22f32c0dba9d8273224907",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\a814810\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sklearn\n",
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "import fasttext\n",
    "import gensim \n",
    "from gensim.models.doc2vec import Doc2Vec, Word2Vec\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from content_based_model import ContentBasedRecommender\n",
    "from evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('./data/articles_clean.csv')\n",
    "articles_lemma = pd.read_csv('./data/articles_lemmatized.csv')"
   ]
  },
  {
   "source": [
    "## Wektoryzacja"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('german') # are there other languages in text"
   ]
  },
  {
   "source": [
    "### Bag of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_vectorizer = CountVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 3), # bi - gram (?)\n",
    "                     min_df=0.01,\n",
    "                     max_df=0.7,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n"
   ]
  },
  {
   "source": [
    "### TFIDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 3), # bi - gram (?)\n",
    "                     min_df=0.01,\n",
    "                     max_df=0.7,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n"
   ]
  },
  {
   "source": [
    "### Word2vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.read_csv('./data/tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content\n",
       "0  ['obligationenfonds', 'fixer', 'laufzeit', 'gi...\n",
       "1                                                 []\n",
       "2  ['e', 'banking', 'ausfall', 'postfinance', 'kä...\n",
       "3  ['terror', 'frankreich', 'louvre', 'macheten',...\n",
       "4  ['unglück', 'panama', 'bus', 'prallt', 'mauer'..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['obligationenfonds', 'fixer', 'laufzeit', 'gi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['e', 'banking', 'ausfall', 'postfinance', 'kä...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['terror', 'frankreich', 'louvre', 'macheten',...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['unglück', 'panama', 'bus', 'prallt', 'mauer'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_list = []\n",
    "for i in range(len(tokens)):\n",
    "    tokens_to_list.append(re.sub('[,\\'\\[\\]]', '', tokens.loc[i][0]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " wv_model = gensim.models.Word2Vec(vector_size=300,min_count=5,workers=10,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3821522, 4225581)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "wv_model.build_vocab(tokens_to_list) \n",
    "wv_model.train(tokens_to_list, total_examples=wv_model.corpus_count, epochs=wv_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('steigt', 0.9997395277023315),\n",
       " ('zählt', 0.9996887445449829),\n",
       " ('performance', 0.9996780157089233),\n",
       " ('inklusive', 0.9996732473373413),\n",
       " ('bundesamt', 0.9996673464775085),\n",
       " ('volle', 0.9996650815010071),\n",
       " ('beinahe', 0.9996550679206848),\n",
       " ('stück', 0.9996546506881714),\n",
       " ('dank', 0.9996422529220581),\n",
       " ('kategorie', 0.999623715877533)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "wv_model.wv.most_similar(positive='institut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "source": [
    "### FastText"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "# wv = load_facebook_model(r'C:\\Users\\a814810\\Downloads\\wiki.de\\wiki.de.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 54.3 s\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasttext_model = fasttext.load_model(r'C:\\Users\\a814810\\Downloads\\wiki.de\\wiki.de.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_lemma"
   ]
  },
  {
   "source": [
    "for i in range(len(articles)):\n",
    "    row = re.sub(r'\\r\\n', '', articles.loc[i,'content'])\n",
    "    embedding = fasttext_model.get_sentence_vector(row)\n",
    "    if i == 0 : fast_matrix = embedding\n",
    "    else: fast_matrix = np.vstack([fast_matrix, embedding])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(22019, 300)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "fast_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_similarity(embedding_1, embedding_2):\n",
    "#     # Calculate the cosine similarity of the two embeddings.\n",
    "#     sim = 1 - cosine(embedding_1, embedding_2)\n",
    "#     print('Cosine similarity: {:.2}'.format(sim))\n",
    "\n",
    "#     # compare the embeddings\n",
    "# cosine_similarity(embedding_1, embedding_2)\n",
    "#     # compare the embeddings\n",
    "# cosine_similarity(embedding_1, embedding_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vectorizer, data): # tylko do tfidf/count (?)\n",
    "    matrix  = vectorizer.fit_transform(data['content'])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return matrix, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = articles['nzz_id'].tolist() # w lemma te same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix, tfidf_features = vectorize(tfidf_vectorizer, articles)\n",
    "# bag_matrix, bag_features = vectorize(bag_vectorizer, articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_lemma, tfidf_features_lemma = vectorize(tfidf_vectorizer, articles_lemma)\n",
    "# bag_matrix_lemma, bag_features_lemma = vectorize(bag_vectorizer, articles_lemma)"
   ]
  },
  {
   "source": [
    "### User profiles (?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "readers = pd.read_csv('./../readers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# users: 1000\n# users with at least 5 interactions: 1000\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = readers.groupby(['id', 'art_id']).size().groupby('id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['id']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# interactions on Train set: 22284\n# interactions on Test set: 5571\n"
     ]
    }
   ],
   "source": [
    "# all users have enough interactions (min 5) so train-test-split basically on readers dataset\n",
    "interactions_train, interactions_test = train_test_split(readers,\n",
    "                                   stratify=readers['id'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=123)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train))\n",
    "print('# interactions on Test set: %d' % len(interactions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_article_profile(item_id: str, matrix):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_articles_profiles(ids,matrix):\n",
    "    item_profiles_list = [get_one_article_profile(x,matrix) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profiles(matrix): \n",
    "    interactions = interactions_train[interactions_train['art_id'].isin(articles['nzz_id'])].set_index('id')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions.index.unique():\n",
    "        user_item_profiles = get_articles_profiles(interactions.loc[person_id,'art_id'],matrix)\n",
    "        user_profiles[person_id] = sklearn.preprocessing.normalize(np.sum(user_item_profiles, axis=0))\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "tfidf_profiles = build_users_profiles(tfidf_matrix)\n",
    "#bag_profiles = build_users_profiles(bag_matrix)\n",
    "len(tfidf_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<22019x2282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1402142 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_matrix_2 = csr_matrix(fast_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<22019x300 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 4470300 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "fast_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_profiles = build_users_profiles(fast_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 2282)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tfidf_profiles[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_profiles_lemma = build_users_profiles(tfidf_matrix_lemma)\n",
    "# bag_profiles_lemma = build_users_profiles(bag_matrix_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2282)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          token  relevance\n",
       "0         insel   0.248814\n",
       "1        papier   0.234971\n",
       "2        frauen   0.227556\n",
       "3           mal   0.216718\n",
       "4       überall   0.210696\n",
       "5            de   0.179554\n",
       "6        leicht   0.177821\n",
       "7     verkaufen   0.174356\n",
       "8         zudem   0.162986\n",
       "9        wasser   0.161277\n",
       "10         hält   0.121477\n",
       "11         weit   0.119935\n",
       "12         meer   0.119870\n",
       "13        wagen   0.117504\n",
       "14       nutzer   0.117485\n",
       "15     vorteile   0.117485\n",
       "16         text   0.115774\n",
       "17      kleiner   0.115630\n",
       "18  technologie   0.114843\n",
       "19  jahrhundert   0.114400"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>insel</td>\n      <td>0.248814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>papier</td>\n      <td>0.234971</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>frauen</td>\n      <td>0.227556</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mal</td>\n      <td>0.216718</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>überall</td>\n      <td>0.210696</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>de</td>\n      <td>0.179554</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>leicht</td>\n      <td>0.177821</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>verkaufen</td>\n      <td>0.174356</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>zudem</td>\n      <td>0.162986</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>wasser</td>\n      <td>0.161277</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>hält</td>\n      <td>0.121477</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>weit</td>\n      <td>0.119935</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>meer</td>\n      <td>0.119870</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>wagen</td>\n      <td>0.117504</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>nutzer</td>\n      <td>0.117485</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>vorteile</td>\n      <td>0.117485</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>text</td>\n      <td>0.115774</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>kleiner</td>\n      <td>0.115630</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>technologie</td>\n      <td>0.114843</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>jahrhundert</td>\n      <td>0.114400</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "myprofile = tfidf_profiles[1]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_features, \n",
    "                        myprofile.flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "source": [
    "## Ewaluator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model = ContentBasedRecommender(item_ids,articles, fast_profiles,fast_matrix_2)\n",
    "model_evaluator = ModelEvaluator()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.07700592353257943, 'recall@10': 0.08741698079339437}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "358             1              1                10       0.1        0.1   \n",
       "721             1              1                10       0.1        0.1   \n",
       "510             0              0                10       0.0        0.0   \n",
       "86              0              1                10       0.0        0.1   \n",
       "484             0              0                10       0.0        0.0   \n",
       "472             1              1                10       0.1        0.1   \n",
       "259             2              2                10       0.2        0.2   \n",
       "264             0              0                10       0.0        0.0   \n",
       "797             0              1                10       0.0        0.1   \n",
       "276             1              2                10       0.1        0.2   \n",
       "\n",
       "     _person_id  \n",
       "358         907  \n",
       "721         938  \n",
       "510          64  \n",
       "86          887  \n",
       "484         397  \n",
       "472         218  \n",
       "259         273  \n",
       "264         803  \n",
       "797         865  \n",
       "276         443  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>907</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>887</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model, articles, readers, interactions_train, interactions_test)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model_3 = ContentBasedRecommender(articles_lemma, bag_profiles_lemma, bag_matrix_lemma)\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.10716208939149165, 'recall@10': 0.11541913480524144}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "358             2              2                10       0.2        0.2   \n",
       "721             1              1                10       0.1        0.1   \n",
       "510             2              2                10       0.2        0.2   \n",
       "86              1              1                10       0.1        0.1   \n",
       "484             2              2                10       0.2        0.2   \n",
       "472             1              3                10       0.1        0.3   \n",
       "259             3              3                10       0.3        0.3   \n",
       "264             0              0                10       0.0        0.0   \n",
       "797             0              3                10       0.0        0.3   \n",
       "276             1              1                10       0.1        0.1   \n",
       "\n",
       "     _person_id  \n",
       "358         907  \n",
       "721         938  \n",
       "510          64  \n",
       "86          887  \n",
       "484         397  \n",
       "472         218  \n",
       "259         273  \n",
       "264         803  \n",
       "797         865  \n",
       "276         443  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>907</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>887</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>0</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_3)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  }
 ]
}