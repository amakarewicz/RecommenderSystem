{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd058acd5bd797a08523d99af27523988877810b63fdf22f32c0dba9d8273224907",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('articles_nlp.csv')\n",
    "articles = articles.drop('content_length', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       nzz_id           author                             catchline  \\\n",
       "0   ld.149648  Claudia Gabriel  Obligationenfonds mit fixer Laufzeit   \n",
       "1  1.18145900          Unknown                               Unknown   \n",
       "2   ld.138769          Unknown                     E-Banking-Ausfall   \n",
       "3   ld.143700          Unknown                  Terror in Frankreich   \n",
       "4   ld.149385          Unknown                     Unglück in Panama   \n",
       "\n",
       "                                             content     department  \\\n",
       "0     obligationenfonds mit fixer laufzeit  es gi...       Finanzen   \n",
       "1                                                          Panorama   \n",
       "2     e banking ausfall  postfinance kämpft mit d...       Finanzen   \n",
       "3     terror in frankreich  louvre nach macheten ...  International   \n",
       "4     unglück in panama  bus prallt gegen eine ma...       Panorama   \n",
       "\n",
       "                                           lead_text                 pub_date  \\\n",
       "0  Die Idee ist gut: Statt einer einzigen Obligat...  2017-03-09 08:01:21.000   \n",
       "1  Zum Auftakt der Fashion Week in New York zeige...  2017-04-11 14:00:29.473   \n",
       "2  Seit Sonntag funktioniert das E-Banking der Po...  2017-01-09 13:55:00.000   \n",
       "3  Einen Tag nach dem Angriff auf Soldaten beim P...  2017-02-04 12:50:25.000   \n",
       "4  Bei einem Busunglück in Panama sind 17 Persone...  2017-03-06 07:31:21.000   \n",
       "\n",
       "                                             title  content_len  \n",
       "0              Es gibt noch interessante Varianten          718  \n",
       "1                            Fashion Week New York            0  \n",
       "2                Postfinance kämpft mit dem System          525  \n",
       "3     Louvre nach Macheten-Angriff wieder geöffnet          181  \n",
       "4  Bus prallt gegen eine Mauer und stürzt in Fluss          110  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nzz_id</th>\n      <th>author</th>\n      <th>catchline</th>\n      <th>content</th>\n      <th>department</th>\n      <th>lead_text</th>\n      <th>pub_date</th>\n      <th>title</th>\n      <th>content_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ld.149648</td>\n      <td>Claudia Gabriel</td>\n      <td>Obligationenfonds mit fixer Laufzeit</td>\n      <td>obligationenfonds mit fixer laufzeit  es gi...</td>\n      <td>Finanzen</td>\n      <td>Die Idee ist gut: Statt einer einzigen Obligat...</td>\n      <td>2017-03-09 08:01:21.000</td>\n      <td>Es gibt noch interessante Varianten</td>\n      <td>718</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.18145900</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td></td>\n      <td>Panorama</td>\n      <td>Zum Auftakt der Fashion Week in New York zeige...</td>\n      <td>2017-04-11 14:00:29.473</td>\n      <td>Fashion Week New York</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ld.138769</td>\n      <td>Unknown</td>\n      <td>E-Banking-Ausfall</td>\n      <td>e banking ausfall  postfinance kämpft mit d...</td>\n      <td>Finanzen</td>\n      <td>Seit Sonntag funktioniert das E-Banking der Po...</td>\n      <td>2017-01-09 13:55:00.000</td>\n      <td>Postfinance kämpft mit dem System</td>\n      <td>525</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ld.143700</td>\n      <td>Unknown</td>\n      <td>Terror in Frankreich</td>\n      <td>terror in frankreich  louvre nach macheten ...</td>\n      <td>International</td>\n      <td>Einen Tag nach dem Angriff auf Soldaten beim P...</td>\n      <td>2017-02-04 12:50:25.000</td>\n      <td>Louvre nach Macheten-Angriff wieder geöffnet</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ld.149385</td>\n      <td>Unknown</td>\n      <td>Unglück in Panama</td>\n      <td>unglück in panama  bus prallt gegen eine ma...</td>\n      <td>Panorama</td>\n      <td>Bei einem Busunglück in Panama sind 17 Persone...</td>\n      <td>2017-03-06 07:31:21.000</td>\n      <td>Bus prallt gegen eine Mauer und stürzt in Fluss</td>\n      <td>110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "source": [
    "### Lematyzacja"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(data): # do zmiany !\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(row) for row in data]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.read_csv('tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content\n",
       "0  ['obligationenfonds', 'fixer', 'laufzeit', 'gi...\n",
       "1                                                 []\n",
       "2  ['e', 'banking', 'ausfall', 'postfinance', 'kä...\n",
       "3  ['terror', 'frankreich', 'louvre', 'macheten',...\n",
       "4  ['unglück', 'panama', 'bus', 'prallt', 'mauer'..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['obligationenfonds', 'fixer', 'laufzeit', 'gi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['e', 'banking', 'ausfall', 'postfinance', 'kä...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['terror', 'frankreich', 'louvre', 'macheten',...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['unglück', 'panama', 'bus', 'prallt', 'mauer'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = articles.loc[0,'content']\n",
    "# lemma = WordNetLemmatizer()\n",
    "# text = lemma.lemmatize(row)\n",
    "# text = \"\".join(text)\n",
    "# text"
   ]
  },
  {
   "source": [
    "## Wektoryzacja"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('german') # are there other languages in text"
   ]
  },
  {
   "source": [
    "### Bag of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_vectorizer = CountVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 3), # bi - gram (?)\n",
    "                     min_df=0.01,\n",
    "                     max_df=0.7,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n"
   ]
  },
  {
   "source": [
    "### TFIDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 3), # bi - gram (?)\n",
    "                     min_df=0.01,\n",
    "                     max_df=0.7,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n"
   ]
  },
  {
   "source": [
    "### Word2vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do "
   ]
  },
  {
   "source": [
    "### FastText"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vectorizer, data): # tylko do tfidf/count (?)\n",
    "    matrix  = vectorizer.fit_transform(data['content'])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return matrix, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = articles['nzz_id'].tolist() # w lemma te same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix, tfidf_features = vectorize(tfidf_vectorizer, articles)\n",
    "# tfidf_matrix_lemma, tfidf_features_lemma = vectorize(tfidf_vectorizer, articles_lemma)\n",
    "bag_matrix, bag_features = vectorize(bag_vectorizer, articles)\n",
    "# bag_matrix_lemma, bag_features_lemma = vectorize(bag_vectorizer, articles_lemma)"
   ]
  },
  {
   "source": [
    "### User profiles (?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "readers = pd.read_csv('./../readers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "readers['eventStrength'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users_interactions_count_df = readers.groupby(['id', 'art_id']).size().groupby('id').size()\n",
    "# print('# users: %d' % len(users_interactions_count_df))\n",
    "# users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['id']]\n",
    "# print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# interactions on Train set: 22284\n# interactions on Test set: 5571\n"
     ]
    }
   ],
   "source": [
    "interactions_train, interactions_test = train_test_split(readers,\n",
    "                                   stratify=readers['id'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=123)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train))\n",
    "print('# interactions on Test set: %d' % len(interactions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_total_ind = readers.set_index('id')\n",
    "interactions_train_ind = interactions_train.set_index('id')\n",
    "interactions_test_ind = interactions_test.set_index('id')\n",
    "\n",
    "def get_items_interacted(person_id, interactions):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions.loc[person_id]['art_id']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1.18331199', 'ld.1293110', 'ld.142559', 'ld.144819', 'ld.154103'}"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "get_items_interacted(1,interactions_total_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To model the user profile, we take all the item profiles the user has interacted and average them. The average is weighted by the interaction strength, in other words, the articles the user has interacted the most (eg. liked or commented) will have a higher strength in the final user profile.\n",
    "\n",
    "def get_item_profile(item_id, matrix):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids,matrix):\n",
    "    item_profiles_list = [get_item_profile(x,matrix) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_indexed_df,matrix):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['art_id'],matrix)\n",
    "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1) # czy potrzebne od tego momentu?\n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "    # return user_item_profiles\n",
    "\n",
    "def build_users_profiles(matrix): \n",
    "    interactions_indexed_df = interactions_train[interactions_train['art_id'] \\\n",
    "                                                   .isin(articles['nzz_id'])].set_index('id')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df,matrix)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<4x2282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 132 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "interactions_ind = interactions_train[interactions_train['art_id'] \\\n",
    "                                                   .isin(articles['nzz_id'])].set_index('id')\n",
    "interactions_person = interactions_ind.loc[1]\n",
    "get_item_profiles(interactions_person['art_id'], tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "tfidf_profiles = build_users_profiles(tfidf_matrix)\n",
    "# tfidf_profiles_lemma = build_users_profiles(tfidf_matrix_lemma)\n",
    "bag_profiles = build_users_profiles(bag_matrix)\n",
    "# bag_profiles_lemma = build_users_profiles(tfidf_matrix_lemma)\n",
    "len(tfidf_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2282)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          token  relevance\n",
       "0         insel   0.248814\n",
       "1        papier   0.234971\n",
       "2        frauen   0.227556\n",
       "3           mal   0.216718\n",
       "4       überall   0.210696\n",
       "5            de   0.179554\n",
       "6        leicht   0.177821\n",
       "7     verkaufen   0.174356\n",
       "8         zudem   0.162986\n",
       "9        wasser   0.161277\n",
       "10         hält   0.121477\n",
       "11         weit   0.119935\n",
       "12         meer   0.119870\n",
       "13        wagen   0.117504\n",
       "14       nutzer   0.117485\n",
       "15     vorteile   0.117485\n",
       "16         text   0.115774\n",
       "17      kleiner   0.115630\n",
       "18  technologie   0.114843\n",
       "19  jahrhundert   0.114400"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>insel</td>\n      <td>0.248814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>papier</td>\n      <td>0.234971</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>frauen</td>\n      <td>0.227556</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mal</td>\n      <td>0.216718</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>überall</td>\n      <td>0.210696</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>de</td>\n      <td>0.179554</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>leicht</td>\n      <td>0.177821</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>verkaufen</td>\n      <td>0.174356</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>zudem</td>\n      <td>0.162986</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>wasser</td>\n      <td>0.161277</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>hält</td>\n      <td>0.121477</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>weit</td>\n      <td>0.119935</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>meer</td>\n      <td>0.119870</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>wagen</td>\n      <td>0.117504</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>nutzer</td>\n      <td>0.117485</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>vorteile</td>\n      <td>0.117485</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>text</td>\n      <td>0.115774</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>kleiner</td>\n      <td>0.115630</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>technologie</td>\n      <td>0.114843</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>jahrhundert</td>\n      <td>0.114400</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "myprofile = tfidf_profiles[1]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_features, \n",
    "                        myprofile.flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None, user_profiles=None, matrix=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        self.user_profiles = user_profiles\n",
    "        self.matrix = matrix\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(self.user_profiles[person_id], self.matrix)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['art_id', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'nzz_id', \n",
    "                                                          right_on = 'nzz_id')[\n",
    "                [\n",
    "                    \"recStrength\",\n",
    "                    \"nzz_id\",\n",
    "                    \"catchline\",\n",
    "                    \"content\",\n",
    "                    \"department\",\n",
    "                    \"lead_text\",\n",
    "                    \"pub_date\",\n",
    "                    \"content_len\"\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "\n",
    "        return recommendations_df"
   ]
  },
  {
   "source": [
    "## Ewaluator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_total_ind)\n",
    "        all_items = set(articles['nzz_id'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_ind.loc[person_id]\n",
    "        if type(interacted_values_testset['art_id']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['art_id'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([(interacted_values_testset['art_id'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_ind), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=123)\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['art_id'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['art_id'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(interactions_test_ind.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model = ContentBasedRecommender(articles, tfidf_profiles,tfidf_matrix)\n",
    "model_evaluator = ModelEvaluator()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.11380362591994256, 'recall@10': 0.12439418416801293}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "358             2              2                10       0.2        0.2   \n",
       "721             1              1                10       0.1        0.1   \n",
       "510             2              2                10       0.2        0.2   \n",
       "86              1              2                10       0.1        0.2   \n",
       "484             2              2                10       0.2        0.2   \n",
       "472             1              2                10       0.1        0.2   \n",
       "259             3              3                10       0.3        0.3   \n",
       "264             0              0                10       0.0        0.0   \n",
       "797             1              2                10       0.1        0.2   \n",
       "276             2              2                10       0.2        0.2   \n",
       "\n",
       "     _person_id  \n",
       "358         907  \n",
       "721         938  \n",
       "510          64  \n",
       "86          887  \n",
       "484         397  \n",
       "472         218  \n",
       "259         273  \n",
       "264         803  \n",
       "797         865  \n",
       "276         443  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>907</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>887</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model_2 = ContentBasedRecommender(articles, bag_profiles, bag_matrix)\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.09639203015616586, 'recall@10': 0.10482857655717107}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "358             2              3                10       0.2        0.3   \n",
       "721             1              1                10       0.1        0.1   \n",
       "510             1              1                10       0.1        0.1   \n",
       "86              1              1                10       0.1        0.1   \n",
       "484             1              2                10       0.1        0.2   \n",
       "472             1              3                10       0.1        0.3   \n",
       "259             1              1                10       0.1        0.1   \n",
       "264             0              0                10       0.0        0.0   \n",
       "797             1              2                10       0.1        0.2   \n",
       "276             2              2                10       0.2        0.2   \n",
       "\n",
       "     _person_id  \n",
       "358         907  \n",
       "721         938  \n",
       "510          64  \n",
       "86          887  \n",
       "484         397  \n",
       "472         218  \n",
       "259         273  \n",
       "264         803  \n",
       "797         865  \n",
       "276         443  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>2</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>907</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>887</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_2)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}