{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd058acd5bd797a08523d99af27523988877810b63fdf22f32c0dba9d8273224907",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting flatten-list\n  Downloading flatten_list-0.2.0-py2.py3-none-any.whl (3.5 kB)\nInstalling collected packages: flatten-list\nSuccessfully installed flatten-list-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flatten-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from pandas.core.common import flatten\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.impute import SimpleImputer\n",
    "from deep_translator import GoogleTranslator\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('articles_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       nzz_id           author                             catchline  \\\n",
       "0   ld.149648  Claudia Gabriel  Obligationenfonds mit fixer Laufzeit   \n",
       "1  1.18145900          Unknown                               Unknown   \n",
       "2   ld.138769          Unknown                     E-Banking-Ausfall   \n",
       "3   ld.143700          Unknown                  Terror in Frankreich   \n",
       "4   ld.149385          Unknown                     Unglück in Panama   \n",
       "\n",
       "                                             content  content_length  \\\n",
       "0     obligationenfonds mit fixer laufzeit  es gi...             704   \n",
       "1                                                                  0   \n",
       "2     e banking ausfall  postfinance kämpft mit d...             523   \n",
       "3     terror in frankreich  louvre nach macheten ...             180   \n",
       "4     unglück in panama  bus prallt gegen eine ma...             117   \n",
       "\n",
       "      department                                          lead_text  \\\n",
       "0       Finanzen  Die Idee ist gut: Statt einer einzigen Obligat...   \n",
       "1       Panorama  Zum Auftakt der Fashion Week in New York zeige...   \n",
       "2       Finanzen  Seit Sonntag funktioniert das E-Banking der Po...   \n",
       "3  International  Einen Tag nach dem Angriff auf Soldaten beim P...   \n",
       "4       Panorama  Bei einem Busunglück in Panama sind 17 Persone...   \n",
       "\n",
       "                  pub_date                                            title  \\\n",
       "0  2017-03-09 08:01:21.000              Es gibt noch interessante Varianten   \n",
       "1  2017-04-11 14:00:29.473                            Fashion Week New York   \n",
       "2  2017-01-09 13:55:00.000                Postfinance kämpft mit dem System   \n",
       "3  2017-02-04 12:50:25.000     Louvre nach Macheten-Angriff wieder geöffnet   \n",
       "4  2017-03-06 07:31:21.000  Bus prallt gegen eine Mauer und stürzt in Fluss   \n",
       "\n",
       "   content_len  \n",
       "0          718  \n",
       "1            0  \n",
       "2          525  \n",
       "3          181  \n",
       "4          110  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nzz_id</th>\n      <th>author</th>\n      <th>catchline</th>\n      <th>content</th>\n      <th>content_length</th>\n      <th>department</th>\n      <th>lead_text</th>\n      <th>pub_date</th>\n      <th>title</th>\n      <th>content_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ld.149648</td>\n      <td>Claudia Gabriel</td>\n      <td>Obligationenfonds mit fixer Laufzeit</td>\n      <td>obligationenfonds mit fixer laufzeit  es gi...</td>\n      <td>704</td>\n      <td>Finanzen</td>\n      <td>Die Idee ist gut: Statt einer einzigen Obligat...</td>\n      <td>2017-03-09 08:01:21.000</td>\n      <td>Es gibt noch interessante Varianten</td>\n      <td>718</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.18145900</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td></td>\n      <td>0</td>\n      <td>Panorama</td>\n      <td>Zum Auftakt der Fashion Week in New York zeige...</td>\n      <td>2017-04-11 14:00:29.473</td>\n      <td>Fashion Week New York</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ld.138769</td>\n      <td>Unknown</td>\n      <td>E-Banking-Ausfall</td>\n      <td>e banking ausfall  postfinance kämpft mit d...</td>\n      <td>523</td>\n      <td>Finanzen</td>\n      <td>Seit Sonntag funktioniert das E-Banking der Po...</td>\n      <td>2017-01-09 13:55:00.000</td>\n      <td>Postfinance kämpft mit dem System</td>\n      <td>525</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ld.143700</td>\n      <td>Unknown</td>\n      <td>Terror in Frankreich</td>\n      <td>terror in frankreich  louvre nach macheten ...</td>\n      <td>180</td>\n      <td>International</td>\n      <td>Einen Tag nach dem Angriff auf Soldaten beim P...</td>\n      <td>2017-02-04 12:50:25.000</td>\n      <td>Louvre nach Macheten-Angriff wieder geöffnet</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ld.149385</td>\n      <td>Unknown</td>\n      <td>Unglück in Panama</td>\n      <td>unglück in panama  bus prallt gegen eine ma...</td>\n      <td>117</td>\n      <td>Panorama</td>\n      <td>Bei einem Busunglück in Panama sind 17 Persone...</td>\n      <td>2017-03-06 07:31:21.000</td>\n      <td>Bus prallt gegen eine Mauer und stürzt in Fluss</td>\n      <td>110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "source": [
    "### Wektoryzacja"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<22019x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1798623 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('german') # are there other languages in text\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2), # bi - gram (?)\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "\n",
    "item_ids = articles['nzz_id'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(articles['content'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix"
   ]
  },
  {
   "source": [
    "### User profiles ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "readers = pd.read_csv('./../readers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id      art_id\n",
       "0   1   ld.154103\n",
       "1   1   ld.142559\n",
       "2   1  1.18331199\n",
       "3   1   ld.144819\n",
       "4   1  ld.1293110"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>art_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ld.154103</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ld.142559</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.18331199</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>ld.144819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>ld.1293110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "readers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "readers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "readers['eventStrength'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# users: 1000\n# users with at least 5 interactions: 1000\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = readers.groupby(['id', 'art_id']).size().groupby('id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['id']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# interactions on Train set: 22284\n# interactions on Test set: 5571\n"
     ]
    }
   ],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(readers,\n",
    "                                   stratify=readers['id'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = readers.set_index('id')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('id')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('id')\n",
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id]['art_id']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        art_id  eventStrength\n",
       "id                           \n",
       "1    ld.154103              1\n",
       "1    ld.142559              1\n",
       "1   1.18331199              1\n",
       "1    ld.144819              1\n",
       "1   ld.1293110              1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>art_id</th>\n      <th>eventStrength</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>ld.154103</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ld.142559</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.18331199</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ld.144819</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ld.1293110</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "interactions_full_indexed_df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1.18331199', 'ld.1293110', 'ld.142559', 'ld.144819', 'ld.154103'}"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "get_items_interacted(1,interactions_full_indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To model the user profile, we take all the item profiles the user has interacted and average them. The average is weighted by the interaction strength, in other words, the articles the user has interacted the most (eg. liked or commented) will have a higher strength in the final user profile.\n",
    "\n",
    "def get_item_profile(item_id):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['art_id'])\n",
    "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "    # return user_item_profiles\n",
    "\n",
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = interactions_train_df[interactions_train_df['art_id'] \\\n",
    "                                                   .isin(articles['nzz_id'])].set_index('id')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<4x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 336 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "interactions_indexed_df = interactions_train_df[interactions_train_df['art_id'] \\\n",
    "                                                   .isin(articles['nzz_id'])].set_index('id')\n",
    "interactions_person_df = interactions_indexed_df.loc[1]\n",
    "get_item_profiles(interactions_person_df['art_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "\n",
    "user_profiles = build_users_profiles()\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 5000)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        token  relevance\n",
       "0       cyber   0.363050\n",
       "1     attacke   0.257250\n",
       "2       insel   0.219441\n",
       "3      frauen   0.200692\n",
       "4     sammeln   0.178919\n",
       "5        bild   0.163145\n",
       "6          de   0.158357\n",
       "7   verkaufen   0.153773\n",
       "8         epa   0.151044\n",
       "9      wasser   0.142238\n",
       "10    angriff   0.124522\n",
       "11  betroffen   0.120192\n",
       "12     tonnen   0.119708\n",
       "13   computer   0.117586\n",
       "14     london   0.115923\n",
       "15    freitag   0.112494\n",
       "16       andy   0.107434\n",
       "17       weit   0.105776\n",
       "18       meer   0.105719\n",
       "19      wagen   0.103632"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cyber</td>\n      <td>0.363050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>attacke</td>\n      <td>0.257250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>insel</td>\n      <td>0.219441</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>frauen</td>\n      <td>0.200692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sammeln</td>\n      <td>0.178919</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bild</td>\n      <td>0.163145</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>de</td>\n      <td>0.158357</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>verkaufen</td>\n      <td>0.153773</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>epa</td>\n      <td>0.151044</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>wasser</td>\n      <td>0.142238</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>angriff</td>\n      <td>0.124522</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>betroffen</td>\n      <td>0.120192</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>tonnen</td>\n      <td>0.119708</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>computer</td>\n      <td>0.117586</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>london</td>\n      <td>0.115923</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>freitag</td>\n      <td>0.112494</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>andy</td>\n      <td>0.107434</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>weit</td>\n      <td>0.105776</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>meer</td>\n      <td>0.105719</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>wagen</td>\n      <td>0.103632</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "myprofile = user_profiles[1]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        myprofile.flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['art_id', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'nzz_id', \n",
    "                                                          right_on = 'nzz_id')[\n",
    "                [\n",
    "                    \"recStrength\",\n",
    "                    \"nzz_id\",\n",
    "                    \"catchline\",\n",
    "                    \"content\",\n",
    "                    \"content_length\"\n",
    "                    \"department\",\n",
    "                    \"lead_text\",\n",
    "                    \"pub_date\",\n",
    "                    \"content_len\"\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles['nzz_id'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['art_id']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['art_id'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([(interacted_values_testset['art_id'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=123)\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['art_id'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['art_id'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.10752109136600252, 'recall@10': 0.11900915455035002}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "686             0              1                10       0.0        0.1   \n",
       "45              2              5                10       0.2        0.5   \n",
       "646             2              3                10       0.2        0.3   \n",
       "106             1              1                10       0.1        0.1   \n",
       "744             1              1                10       0.1        0.1   \n",
       "236             0              0                10       0.0        0.0   \n",
       "422             2              2                10       0.2        0.2   \n",
       "423             2              2                10       0.2        0.2   \n",
       "217             0              0                10       0.0        0.0   \n",
       "254             2              2                10       0.2        0.2   \n",
       "\n",
       "     _person_id  \n",
       "686         443  \n",
       "45          197  \n",
       "646         397  \n",
       "106           8  \n",
       "744          47  \n",
       "236         513  \n",
       "422         803  \n",
       "423         865  \n",
       "217         208  \n",
       "254         100  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>686</th>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>443</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>2</td>\n      <td>5</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.5</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>646</th>\n      <td>2</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>513</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>208</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}