{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd058acd5bd797a08523d99af27523988877810b63fdf22f32c0dba9d8273224907",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\a814810\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sklearn\n",
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "import fasttext\n",
    "import gensim \n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from content_based_model import ContentBasedRecommender\n",
    "from evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('./data/articles_clean.csv')\n",
    "articles_lemma = pd.read_csv('./data/articles_lemmatized.csv')"
   ]
  },
  {
   "source": [
    "## Wektoryzacja"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('german') # are there other languages in text"
   ]
  },
  {
   "source": [
    "### Bag of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_vectorizer = CountVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 3), # bi - gram (?)\n",
    "                     min_df=0.01,\n",
    "                     max_df=0.7,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n"
   ]
  },
  {
   "source": [
    "### TFIDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 3), # bi - gram (?)\n",
    "                     min_df=0.01,\n",
    "                     max_df=0.7,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n"
   ]
  },
  {
   "source": [
    "### Word2vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.read_csv('./data/tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do "
   ]
  },
  {
   "source": [
    "### FastText"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "model.bin cannot be opened for loading!",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-834f2596e6e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# to do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"some string\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 1 sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvect2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# for text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fasttext\\FastText.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;34m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0meprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fasttext\\FastText.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, args)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfasttext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: model.bin cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "# to do \n",
    "model = fasttext.load_model('model.bin')\n",
    "vect = model.get_sentence_vector(\"some string\") # 1 sentence\n",
    "vect2 = [model.get_sentence_vector(el.replace('\\n', '')) for el in text] # for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vectorizer, data): # tylko do tfidf/count (?)\n",
    "    matrix  = vectorizer.fit_transform(data['content'])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return matrix, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = articles['nzz_id'].tolist() # w lemma te same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix, tfidf_features = vectorize(tfidf_vectorizer, articles)\n",
    "# bag_matrix, bag_features = vectorize(bag_vectorizer, articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_lemma, tfidf_features_lemma = vectorize(tfidf_vectorizer, articles_lemma)\n",
    "# bag_matrix_lemma, bag_features_lemma = vectorize(bag_vectorizer, articles_lemma)"
   ]
  },
  {
   "source": [
    "### User profiles (?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "readers = pd.read_csv('./../readers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# users: 1000\n# users with at least 5 interactions: 1000\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = readers.groupby(['id', 'art_id']).size().groupby('id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['id']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# interactions on Train set: 22284\n# interactions on Test set: 5571\n"
     ]
    }
   ],
   "source": [
    "# all users have enough interactions (min 5) so train-test-split basically on readers dataset\n",
    "interactions_train, interactions_test = train_test_split(readers,\n",
    "                                   stratify=readers['id'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=123)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train))\n",
    "print('# interactions on Test set: %d' % len(interactions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_article_profile(item_id: str, matrix):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_articles_profiles(ids,matrix):\n",
    "    item_profiles_list = [get_one_article_profile(x,matrix) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profiles(matrix): \n",
    "    interactions = interactions_train[interactions_train['art_id'].isin(articles['nzz_id'])].set_index('id')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions.index.unique():\n",
    "        user_item_profiles = get_articles_profiles(interactions.loc[person_id,'art_id'],matrix)\n",
    "        user_profiles[person_id] = sklearn.preprocessing.normalize(np.sum(user_item_profiles, axis=0))\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tfidf_profiles = build_users_profiles(tfidf_matrix)\n",
    "#bag_profiles = build_users_profiles(bag_matrix)\n",
    "len(tfidf_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 2282)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tfidf_profiles[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_profiles_lemma = build_users_profiles(tfidf_matrix_lemma)\n",
    "# bag_profiles_lemma = build_users_profiles(bag_matrix_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2282)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          token  relevance\n",
       "0         insel   0.248814\n",
       "1        papier   0.234971\n",
       "2        frauen   0.227556\n",
       "3           mal   0.216718\n",
       "4       체berall   0.210696\n",
       "5            de   0.179554\n",
       "6        leicht   0.177821\n",
       "7     verkaufen   0.174356\n",
       "8         zudem   0.162986\n",
       "9        wasser   0.161277\n",
       "10         h채lt   0.121477\n",
       "11         weit   0.119935\n",
       "12         meer   0.119870\n",
       "13        wagen   0.117504\n",
       "14       nutzer   0.117485\n",
       "15     vorteile   0.117485\n",
       "16         text   0.115774\n",
       "17      kleiner   0.115630\n",
       "18  technologie   0.114843\n",
       "19  jahrhundert   0.114400"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>insel</td>\n      <td>0.248814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>papier</td>\n      <td>0.234971</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>frauen</td>\n      <td>0.227556</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mal</td>\n      <td>0.216718</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>체berall</td>\n      <td>0.210696</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>de</td>\n      <td>0.179554</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>leicht</td>\n      <td>0.177821</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>verkaufen</td>\n      <td>0.174356</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>zudem</td>\n      <td>0.162986</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>wasser</td>\n      <td>0.161277</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>h채lt</td>\n      <td>0.121477</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>weit</td>\n      <td>0.119935</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>meer</td>\n      <td>0.119870</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>wagen</td>\n      <td>0.117504</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>nutzer</td>\n      <td>0.117485</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>vorteile</td>\n      <td>0.117485</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>text</td>\n      <td>0.115774</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>kleiner</td>\n      <td>0.115630</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>technologie</td>\n      <td>0.114843</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>jahrhundert</td>\n      <td>0.114400</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "myprofile = tfidf_profiles[1]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_features, \n",
    "                        myprofile.flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "source": [
    "## Ewaluator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model = ContentBasedRecommender(item_ids,articles, tfidf_profiles,tfidf_matrix)\n",
    "model_evaluator = ModelEvaluator()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.10375157063363849, 'recall@10': 0.12457368515526836}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "358             2              2                10       0.2        0.2   \n",
       "721             0              1                10       0.0        0.1   \n",
       "510             0              2                10       0.0        0.2   \n",
       "86              2              2                10       0.2        0.2   \n",
       "484             2              2                10       0.2        0.2   \n",
       "472             1              2                10       0.1        0.2   \n",
       "259             2              3                10       0.2        0.3   \n",
       "264             0              0                10       0.0        0.0   \n",
       "797             2              2                10       0.2        0.2   \n",
       "276             2              2                10       0.2        0.2   \n",
       "\n",
       "     _person_id  \n",
       "358         907  \n",
       "721         938  \n",
       "510          64  \n",
       "86          887  \n",
       "484         397  \n",
       "472         218  \n",
       "259         273  \n",
       "264         803  \n",
       "797         865  \n",
       "276         443  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>907</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>0</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>887</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>2</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model, articles, readers, interactions_train, interactions_test)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model_3 = ContentBasedRecommender(articles_lemma, bag_profiles_lemma, bag_matrix_lemma)\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "999 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.10716208939149165, 'recall@10': 0.11541913480524144}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "358             2              2                10       0.2        0.2   \n",
       "721             1              1                10       0.1        0.1   \n",
       "510             2              2                10       0.2        0.2   \n",
       "86              1              1                10       0.1        0.1   \n",
       "484             2              2                10       0.2        0.2   \n",
       "472             1              3                10       0.1        0.3   \n",
       "259             3              3                10       0.3        0.3   \n",
       "264             0              0                10       0.0        0.0   \n",
       "797             0              3                10       0.0        0.3   \n",
       "276             1              1                10       0.1        0.1   \n",
       "\n",
       "     _person_id  \n",
       "358         907  \n",
       "721         938  \n",
       "510          64  \n",
       "86          887  \n",
       "484         397  \n",
       "472         218  \n",
       "259         273  \n",
       "264         803  \n",
       "797         865  \n",
       "276         443  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hits@5_count</th>\n      <th>hits@10_count</th>\n      <th>interacted_count</th>\n      <th>recall@5</th>\n      <th>recall@10</th>\n      <th>_person_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>907</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>938</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>887</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>803</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>0</td>\n      <td>3</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>865</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_3)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  }
 ]
}